
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>CVPR'21 Online Tutorial on Interpretable Machine Learning in Computer Vision</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
</head>

<body> 

<div class="container">

  <table border="0" align="center">
    <tr>
      <td width="750" align="center" valign="middle"><h3>IJCAI 2021 Tutorial</h3>
      <span class="title"> Neural Machine Reasoning</span></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><h3>Time: TBD<br></h3></td>
    </tr>
  </table>
  This tutorial reviews recent advances on dynamic neural networks that aim to reach a deliberative reasoning capability. This goes beyond the current associative pattern matching excelled by deep learning.
 <!--  <p><img src="figures/main_ijcai2021.png" width="1000" align="middle" /></p> -->

</div>

</br>

<div class="container">
  <h2>Tutorial Lecturers</h2>
    <div>
      <div class="instructor">
          <a href="https://truyentran.github.io/" >
        <div class="instructorphoto"><img src="figures/truyen.jpg"></div>
        <div>Truyen Tran</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://vuongle2.github.io/">
            <div class="instructorphoto"><img src="figures/vuong.jpg"></div>
            <div>Vuong Le</div>
        </a>
      </div>

      <div class="instructor">
          <a href="https://thaolmk54.github.io/">
        <div class="instructorphoto"><img src="figures/hung.jpg"></div>
        <div>Hung Thai Le</div>
        </a>
      </div>

      <div class="instructor">
        <a href="https://thaihungle.github.io/">
            <div class="instructorphoto"><img src="figures/thao.jpg"></div>
            <div>Thao Minh Le</div>
        </a>
      </div>


    </div>
    <div>
    <p></p>
    <a href="https://a2i2.deakin.edu.au/">
    Applied AI Institute, Deakin University, Australia
    </a>
    </div>
    <p></p> 
</div>   

</br>

<div class="container">
  <h2>Overview</h2>
    <div class="overview">

      <p> </p>

      <p>Current machine learning, powered by deep neural networks, excels at extracting predictive patterns from loads of data and training signals. In the past seven years, there has been a steady growth in extending this capability to the field of reasoning – the capacity to deliberately deduce new knowledge out of the existing knowledge base. This tutorial presents an organized body of knowledge that covers the recent developments around this conjunction of machine learning and reasoning with focus on differentiable neural network architectures. The main question we want to answer is whether we can learn to reason from data in the same way that we can learn to predict using neural networks? In this tutorial, we will show how this is achievable by using dynamic neural networks whose computational graphs are composed on-the-fly given data and query. Here the query is arbitrary, e.g., in linguistic form. The data and the domain have structures spanned both in space and time, i.e., data elements are interlinked by relations either implicitly or explicitly. Covered topics are organized into two parts, theory and applications. The theory part consists of dual–system account of reasoning, neural memories, reasoning over unstructured sets and over structured graphs, and neuro–symbolic integration. The applications part covers neural reasoning in machine reading comprehension, visual question answering and combinatorial inference. </p>

    </div>
</div>

</br>

<div class="container">
  <h2>Schedule</h2>
    <div class="schedule">
        <h3>Part 1: Theory (180 mins)</h3>
        This part is further divided into six sub-topics: concepts, dual process theories, neural memories, reasoning over sets, reasoning over graphs, and neuro-symbolic integration.
<h4> Lecture 1: Concepts in neural machine reasoning (30 mins) </h4> In this part, we will review the key concepts of learning and reasoning, and how these two intelligence faculties interact. In particular, we will start with the formal framework of learning to reason, where the task is to determine if the data entails a conclusion [23]. We then show how question answering and most of supervised machine learning tasks can be reformulated under this framework. We then explain how modern neural networks can serve as an underlying mechanism for learning and reasoning in this framework. One of the key components is attention, which is found in most recent works. We also discuss how reasoning can also be considered as an instance of conditional computation where the computational graphs are dynamically co-determined by the query in conjunction with available data. An extreme form of this is program synthesis, where a predicate-chaining program is automatically generated from the query in the context of the data, and the execution of the program will deliver the answer.

<h4> Lecture 2: Dual system of reasoning (30 mins)</h4>  We will briefly review a well-established framework in human reasoning known as dual-process theories [11], otherwise known informally as fast and slow thinking [22]. This topic is of great importance in recent years within the AI community, e.g., as discussed in the AAAI panel 2019 with attendance of Nobel laureate Kahneman and Turing Award winner Joshua Bengio. In particular, the fast thinking process, also known as System 1, is typically parallel, reactive and domain-specific, and it is equivalent to most of current deep learning models. On the other hand, the slow thinking process, also known as System 2, is sequential, deliberative and domain-agnostic. We will explain how System 2 plays the role in core reasoning forms, including compositional, relational, temporal and causal reasoning. Finally, we will discuss how System 1 and System 2 interact.
<h4> Lecture 3: Neural memories (30 mins) </h4> For this part, we cover one of the most essential aspect that underlies the reasoning process: the memory [12] – a mental faculty that allows us to remember, retrieve, manipulate information and simulate unseen scenarios. We will cover three distinct concepts that are essential for high-order reasoning: memory of entities, memory of relations, and memory of programs. Neural memory for entities has been widely studied, and this goes under the umbrella of Memory-Augmented Neural Networks [18, 47, 49]. Less studied, but extremely essential to high-order reasoning, is memory of relations which allows us to explicitly store, retrieve and manipulate known and freshly formed relations in the long predicate-chaining process [24]. We will describe how relation memory is implemented, using either tensors [28, 42, 45] or graphs [37]. In these models, attention is the common operator to leverage the relationship modeling. Finally, we will explain how a powerful recent concept known as program memory will be essential for conditional computation and automatic neural program synthesis – the underlying computational processes behind reasoning. Two approaches to program memory are covered: the modular neural networks [2], and the stored-program memory [27].
<h4> Lecture 4: Reasoning over unstructured sets (30 mins) </h4> Much of recent works involved neural reasoning can be formulated as reasoning over unstructured sets. In these settings we have a set of query words, and a set of items in the knowledge base (which can be words in text or extracted visual features in image). The task of reasoning is to construct a sequential process in that the items in the two sets are iteratively attended to and interact in a compositional way. This could be an iterative conditioning process [39], or a recurrent model of composition and attention [17, 21].
<h4> Lecture 5: Reasoning over graphs (30 mins) </h4> Relational structures have been demonstrated to be crucial for reasoning [15, 50], and these are conveniently and expressively represented as graphs [5]. This leads to graph reasoning, which occurs when reasoning is structured as or supported by operations on graphs. In this part, we will explain how graph neural networks serve as an underlying backbone for relational reasoning, both in space and time [6]. We will cover basic concepts including node embedding, relational networks [43] and message passing; and advanced topics such as query-conditioned graph construction [29] and graph dynamics [38].
<h4> Lecture 6: Hybrid neuro-symbolic reasoning (30 mins) </h6> Theory of neural reasoning cannot be complete without a link to the symbolic approach [14]. This is because the symbolic approach lends itself easily to high-level logical inference, which is important in many NLP and mathematical reasoning problems. In addition, symbolic approach seems to be more natural to deal with important issues such as systematic generalization in which pure neural networks are not very effective yet [3, 13]. In this sub-topic of hybrid neuro-symbolic reasoning, we will cover recent works including neural module networks [19, 53] and the integration of logical models and neural networks [14].
        <h3>Part 2: Application (180 mins) </h3>
        A powerful way to demonstrate capability of learning to reason is answering natural questions about data that are unstructured (such as text) or come directly out of sensing devices (such as image and video). In recent years, textual QA or visual QA have been investigated intensively. However, much of existing work exploits pattern matching capability of generic techniques such as RNN and attention to exploit statistics in data rather than constructing a generic, explicit reasoning machines [21]. The current trend set by these works pushes the sophistication of the reasoning processes on finding the correlation between data pattern and the query. Pattern recognition and reasoning are tightly entangled, and reasoning tends to be specific to visual/textual patterns as a results. However, generalization to novel patterns will suffer as a result – the argument has been put forward 30 years ago [13], and has not been proven wrong [7].
This part is organized into four topics: machine reading comprehension, dual architectures in visual question answering, specific aspects of visual question answering, and reasoning over combinatorial domains.

<h4> Lecture 7: Neural machine reading comprehension (Text-based QA) (45 mins) </h4> This section will review the most important works in the past 5 years, starting from RNN-based methods with attention mechanisms
[46] to modern transformer-based architectures [51, 55]. We will also discuss the current growing trend of leveraging pre-trained language models such as BERT [10], GPTs [41] in machine reading comprehension. Task-agnostic models can be pre-trained on a large corpus returning more holistic concept representations of words with contextual information. Those representations can then be transferred to various down-stream tasks including question answering with a fine-tuning process [56]. By doing that, the field is moving from conventional approaches of having dual processes, namely feature encoding and reasoning, into having an integrated architecture of a single module to carry out both processes at once.
<h4> Lecture 8:Visual question answering (45 mins) </h4> VQA presents one of the most exciting venues for neural networks because it sits at the intersection between four distinct domains: machine learning, reasoning, computer vision and NLP. The reasoning problem in VQA can be organized according to the dual process framework [31], that is, there are two interacting components: System 1 (modality-specific pattern extraction), and System 2 (generic reasoning process with symbol binding). System 1 for visual data can be developed on top of 2D/3D CNN, but needs special consideration to support compositional/relational reasoning [26]. We then advance to object-centric representation, that is, a scene is represented as a set of interacting objects in space-time instead of an array of pixels [9]. Recent improvement in performance in object detection (e.g., Faster R-CNN, YOLO, Deformable DETR) makes this approach possible. Not only object-centric representation makes relational reasoning more straightforward, it also enables a seamless data input for System 2, making the joint dual system closer to a neuro-symbolic hybrid. System 2, in addition to being generic, would also require the ability of symbol binding [29], dynamic construction of visual graphs [20, 34], and chaining of predicates [21, 29].
<h4> Lecture 9: Video question answering (45 mins) </h4> Video QA opens up new challenges with multimodality– grounded temporal and causal reasoning. Activities and actions are much more lively in videos than static images. Temporal structures of activity such as hierarchy [36], continuity and non-local referencing require complex reasoning [30]. Furthermore, temporal reasoning is distinctive because temporal structure (not like spatial) has an universal direction (only going forward). This opens playground for causal, counterfactual hypothetical reasoning which are extremely attractive yet less explored [52]. Cross-modality reasoning: Visual information and linguistic query naturally lie in different domains; therefore, cross-domain interaction is crucial in this problem. How cross-domain objects interact (cross-reference, binding, combination) is key for human reasoning and also for machine reasoning to succeed [29]. Reasoning on long-form videos containing interleaving multimodal data (visual, caption, audio) appeals the even more advanced multi-modality interaction capability. This provides playground for complex reasoning systems where information pieces from all modalities can be picked, combined, and reasoned on [32].

<h4> Lecture 10: Combinatorics reasoning (45 mins) </h4> Combinatorial problems represent an important class of reason- ing, which are usually difficult to solve [16, 35, 44]. We will present how neural networks such as pointer networks [48] and graph neural networks [6], coupled with reinforcement learning, are effective in learning to solve these problems [57]. Examples include inference in probabilistic graphical models [4, 25, 54], finding shortest paths [18], traveling salesman problems [28, 40], graph coloring [33] and substructures counting [1, 8].
        <h3>Panel Discussion</h3>
    </div>
</div>

</br>

<div class="containersmall">
    <p>Please contact <a href="mailto:truyen.tran@deakin.edu.au">Truyen Tran</a> if you have question.</p>
</div>
 
<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
